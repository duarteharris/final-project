{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the work enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import plac\n",
    "import random\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version: 2.2.4\n",
      "nltk version: 3.4.5\n",
      "numpy version: 1.18.1\n",
      "pandas version: 1.0.1\n",
      "plaidml version: 0.7.0\n",
      "re version: 2.2.1\n",
      "Seaborn version: 0.10.0\n",
      "spacy version: 2.0.12\n"
     ]
    }
   ],
   "source": [
    "# Versions\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"re version:\", re.__version__)\n",
    "print(\"Seaborn version:\", sns.__version__)\n",
    "print(\"spacy version:\", spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories & Files\n",
    "os.listdir()\n",
    "\n",
    "# Datasets directory\n",
    "directory = \"./datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataturks_to_spacy(JSON_FilePath):\n",
    "\n",
    "    training_data = list()\n",
    "    lines = list()\n",
    "        \n",
    "    with open(JSON_FilePath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "        text = data[\"content\"]\n",
    "        entities = []\n",
    "        \n",
    "        for annotation in data[\"annotation\"]:\n",
    "            #only a single point in text annotation.\n",
    "            point = annotation[\"points\"][0]\n",
    "            labels = annotation[\"label\"]\n",
    "                \n",
    "            # handle both list of labels or a single label.\n",
    "            if not isinstance(labels, list):\n",
    "                labels = [labels]\n",
    "\n",
    "            for label in labels:\n",
    "                #these indices are both inclusive [start, end] but spacy is not \n",
    "                # [start, end)\n",
    "                #entities.append((point[\"start\"], point[\"end\"] + 1 ,label))\n",
    "                entities.append((point[\"start\"], point[\"end\"] + 1 ,label))\n",
    "\n",
    "\n",
    "        training_data.append((text, {\"entities\" : entities}))\n",
    "\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_dataturks_to_spacy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4cebb29ad685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTRAIN_DATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_dataturks_to_spacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"cv_traindata.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'convert_dataturks_to_spacy' is not defined"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = convert_dataturks_to_spacy(directory + \"cv_traindata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TRAIN_DATA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bcbf05f6c58b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'TRAIN_DATA' is not defined"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.58 s, sys: 810 ms, total: 7.39 s\n",
      "Wall time: 7.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Creating a NLP object // Loading the model\n",
    "#nlp = spacy.load(\"en_core_web_sm\") # 11MB\n",
    "#nlp = spacy.load(\"en_core_web_md\") # 91MB\n",
    "nlp = spacy.load(\"en_core_web_lg\") # 789MB\n",
    "#nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the ner pipe, and adding it to the pipeline (if it's not there already)\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(ner, last = True)\n",
    "    \n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding labels\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:00<00:23,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statring iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:29<00:00,  6.79it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 22648.764003465345}\n",
      "Statring iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:30<00:00,  6.58it/s]\n",
      "  0%|          | 1/200 [00:00<00:38,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 21429.838546635037}\n",
      "Statring iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:29<00:00,  6.68it/s]\n",
      "  0%|          | 1/200 [00:00<00:20,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 21101.109041517266}\n",
      "Statring iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [00:12<00:20,  5.93it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        \n",
    "        for itn in range(10):\n",
    "            print(\"Statring iteration \" + str(itn))\n",
    "            \n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            \n",
    "            losses = {}\n",
    "            \n",
    "            for text, annotations in tqdm(TRAIN_DATA):\n",
    "                nlp.update(\n",
    "                    [text],  # batch of texts\n",
    "                    [annotations],  # batch of annotations\n",
    "                    drop = 0.2,  # dropout - make it harder to memorise data\n",
    "                    sgd = optimizer,  # callable to update weights\n",
    "                    losses = losses)\n",
    "                \n",
    "            print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model and evaluate it\n",
    "examples = convert_dataturks_to_spacy(directory + \"cv_testdata.json\")\n",
    "tp=0\n",
    "tr=0\n",
    "tf=0\n",
    "\n",
    "ta=0\n",
    "c=0        \n",
    "\n",
    "for text,annot in examples:\n",
    "    f=open(\"resume\"+str(c)+\".txt\",\"w\")\n",
    "    doc_to_test=nlp(text)\n",
    "    d={}\n",
    "    for ent in doc_to_test.ents:\n",
    "        d[ent.label_]=[]\n",
    "    for ent in doc_to_test.ents:\n",
    "        d[ent.label_].append(ent.text)\n",
    "\n",
    "    for i in set(d.keys()):\n",
    "\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(i +\":\"+\"\\n\")\n",
    "        for j in set(d[i]):\n",
    "            f.write(j.replace('\\n','')+\"\\n\")\n",
    "    d={}\n",
    "    for ent in doc_to_test.ents:\n",
    "        d[ent.label_]=[0,0,0,0,0,0]\n",
    "    for ent in doc_to_test.ents:\n",
    "        doc_gold_text= nlp.make_doc(text)\n",
    "        gold = GoldParse(doc_gold_text, entities=annot.get(\"entities\"))\n",
    "        y_true = [ent.label_ if ent.label_ in x else 'Not '+ent.label_ for x in gold.ner]\n",
    "        y_pred = [x.ent_type_ if x.ent_type_ ==ent.label_ else 'Not '+ent.label_ for x in doc_to_test]  \n",
    "        if(d[ent.label_][0]==0):\n",
    "            #f.write(\"For Entity \"+ent.label_+\"\\n\")   \n",
    "            #f.write(classification_report(y_true, y_pred)+\"\\n\")\n",
    "            (p,r,f,s)= precision_recall_fscore_support(y_true,y_pred,average='weighted')\n",
    "            a=accuracy_score(y_true,y_pred)\n",
    "            d[ent.label_][0]=1\n",
    "            d[ent.label_][1]+=p\n",
    "            d[ent.label_][2]+=r\n",
    "            d[ent.label_][3]+=f\n",
    "            d[ent.label_][4]+=a\n",
    "            d[ent.label_][5]+=1\n",
    "    c+=1\n",
    "for i in d:\n",
    "    print(\"\\n For Entity \"+i+\"\\n\")\n",
    "    print(\"Accuracy : \"+str((d[i][4]/d[i][5])*100)+\"%\")\n",
    "    print(\"Precision : \"+str(d[i][1]/d[i][5]))\n",
    "    print(\"Recall : \"+str(d[i][2]/d[i][5]))\n",
    "    print(\"F-score : \"+str(d[i][3]/d[i][5]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
